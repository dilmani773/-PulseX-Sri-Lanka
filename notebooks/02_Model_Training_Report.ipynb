{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3a394f",
   "metadata": {},
   "source": [
    "### 1. setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbf4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "if str(Path.cwd().parent) not in sys.path:\n",
    "    sys.path.append(str(Path.cwd().parent))\n",
    "    \n",
    "# Import the actual training pipeline\n",
    "from src.train_models import ModelTrainingPipeline\n",
    "from src.config import MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be4b6c",
   "metadata": {},
   "source": [
    "### 2. Execute production training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bff8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.train_models:Loading historical data...\n",
      "INFO:src.train_models:Loaded 1096 days of historical data\n",
      "INFO:src.train_models:Preparing training features...\n",
      "INFO:src.train_models:Prepared features shape: (1096, 15)\n",
      "INFO:src.train_models:Training anomaly detector...\n",
      "INFO:src.train_models:Loaded 1096 days of historical data\n",
      "INFO:src.train_models:Preparing training features...\n",
      "INFO:src.train_models:Prepared features shape: (1096, 15)\n",
      "INFO:src.train_models:Training anomaly detector...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production Model Training Pipeline (src/train_models.py)...\n",
      "This will load historical data, train models, and save artifacts.\n",
      "\n",
      "======================================================================\n",
      "PULSEX SRI LANKA - MODEL TRAINING PIPELINE\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.train_models:Anomaly detector trained. Detected 1 anomalies\n",
      "INFO:src.train_models:Saved model to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\\anomaly_detector.pkl\n",
      "INFO:src.train_models:Training risk scorer...\n",
      "INFO:src.train_models:Saved model to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\\anomaly_detector.pkl\n",
      "INFO:src.train_models:Training risk scorer...\n",
      "INFO:src.train_models:Risk scorer trained (Bayesian priors updated)\n",
      "INFO:src.train_models:Saved model to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\\risk_scorer.pkl\n",
      "INFO:src.train_models:Risk scorer trained (Bayesian priors updated)\n",
      "INFO:src.train_models:Saved model to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\\risk_scorer.pkl\n",
      "INFO:src.train_models:Analyzing trends...\n",
      "INFO:src.train_models:Overall trend: decreasing, strength: 0.650\n",
      "INFO:src.train_models:Saved trend analysis to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\processed\\trend_analysis.json\n",
      "INFO:src.train_models:Generating training report...\n",
      "INFO:src.train_models:Saved training report to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\\training_report.json\n",
      "INFO:src.train_models:Analyzing trends...\n",
      "INFO:src.train_models:Overall trend: decreasing, strength: 0.650\n",
      "INFO:src.train_models:Saved trend analysis to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\processed\\trend_analysis.json\n",
      "INFO:src.train_models:Generating training report...\n",
      "INFO:src.train_models:Saved training report to c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\\training_report.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "✅ TRAINING COMPLETE!\n",
      "======================================================================\n",
      "Trained on 1096 days of data\n",
      "Models saved to: c:\\Users\\WW\\Documents\\modelX final round try 2\\data\\models\n",
      "\n",
      "Trained models:\n",
      "  • anomaly_detector: Hybrid Ensemble\n",
      "  • risk_scorer: Bayesian\n",
      "  • sentiment_analyzer: Rule-based\n",
      "  • trend_analyzer: Statistical\n",
      "\n",
      "Next step: Run dashboard to see predictions\n",
      "  streamlit run src/dashboard/app.py\n",
      "======================================================================\n",
      "\n",
      "\n",
      " Training pipeline executed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Running production Model Training Pipeline (src/train_models.py)...\")\n",
    "print(\"This will load historical data, train models, and save artifacts.\")\n",
    "\n",
    "# Initialize and run the training script\n",
    "try:\n",
    "    pipeline = ModelTrainingPipeline()\n",
    "    # Run the full training routine (load -> prep -> train -> save)\n",
    "    pipeline.run_complete_training()\n",
    "    print(\"\\n Training pipeline executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n WARNING: Training pipeline encountered an error: {e}\")\n",
    "    # Continue to model verification, assuming a previous run was successful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26fd61e",
   "metadata": {},
   "source": [
    "### Model artifact verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b980f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying necessary model artifacts:\n",
      "  [FOUND] anomaly_detector.pkl\n",
      "  [FOUND] risk_scorer.pkl\n",
      "  [FOUND] training_report.json\n",
      "\n",
      " All production models are verified and ready for deployment.\n"
     ]
    }
   ],
   "source": [
    "required_models = [\n",
    "    'anomaly_detector.pkl', \n",
    "    'risk_scorer.pkl',\n",
    "    'training_report.json'\n",
    "]\n",
    "\n",
    "print(\"\\nVerifying necessary model artifacts:\")\n",
    "all_found = True\n",
    "for model_file in required_models:\n",
    "    path = MODELS_DIR / model_file\n",
    "    if path.exists():\n",
    "        print(f\"  [FOUND] {model_file}\")\n",
    "    else:\n",
    "        print(f\"  [MISSING] {model_file} - Pipeline needs fixing or rerun.\")\n",
    "        all_found = False\n",
    "\n",
    "if all_found:\n",
    "    print(\"\\n All production models are verified and ready for deployment.\")\n",
    "else:\n",
    "    print(\"\\n CRITICAL: Missing model artifacts. Cannot proceed to evaluation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
