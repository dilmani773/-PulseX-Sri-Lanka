{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db34f94",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Data Exploration\n",
    "\n",
    "This notebook explores the scraped data and provides insights into patterns, \n",
    "distributions, and characteristics of Sri Lankan news and social media data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebce31",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbe353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140959e",
   "metadata": {},
   "source": [
    "### Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ba64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import RAW_DATA_DIR, PROCESSED_DATA_DIR\n",
    "from preprocessing.text_cleaner import TextCleaner\n",
    "from models.sentiment_engine import SentimentAnalyzer\n",
    "\n",
    "print(\"âœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8435a",
   "metadata": {},
   "source": [
    "### 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a9167",
   "metadata": {},
   "source": [
    "### Find the most recent news data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_files = list(RAW_DATA_DIR.glob('news_*.json'))\n",
    "if news_files:\n",
    "    latest_file = max(news_files, key=lambda x: x.stat().st_mtime)\n",
    "    print(f\"Loading: {latest_file}\")\n",
    "    \n",
    "    with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "        news_data = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame(news_data)\n",
    "    df['scraped_at'] = pd.to_datetime(df['scraped_at'])\n",
    "    df['published_date'] = pd.to_datetime(df['published_date'])\n",
    "    \n",
    "    print(f\"\\nâœ“ Loaded {len(df)} articles\")\n",
    "    print(f\"Date range: {df['scraped_at'].min()} to {df['scraped_at'].max()}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No data files found. Run the scraper first: python src/data_ingestion/news_scraper.py\")\n",
    "    # Create sample data for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'title': [f'Sample article {i}' for i in range(100)],\n",
    "        'source': np.random.choice(['Ada Derana', 'Daily Mirror', 'Hiru News'], 100),\n",
    "        'category': np.random.choice(['Political', 'Economic', 'Social'], 100),\n",
    "        'language': np.random.choice(['en', 'si'], 100),\n",
    "        'scraped_at': pd.date_range(end=datetime.now(), periods=100, freq='1H')\n",
    "    })\n",
    "    print(\"âœ“ Created sample data for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fedff9",
   "metadata": {},
   "source": [
    "### 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total articles: {len(df)}\")\n",
    "print(f\"Date range: {(df['scraped_at'].max() - df['scraped_at'].min()).days} days\")\n",
    "print(f\"Unique sources: {df['source'].nunique()}\")\n",
    "print(f\"Categories: {df['category'].nunique()}\")\n",
    "print(f\"Languages: {df['language'].value_counts().to_dict()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c397bb",
   "metadata": {},
   "source": [
    "### 4. Source Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590842fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e84d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles by source\n",
    "source_counts = df['source'].value_counts()\n",
    "axes[0].bar(source_counts.index, source_counts.values, color='steelblue')\n",
    "axes[0].set_title('Articles by Source', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Source')\n",
    "axes[0].set_ylabel('Number of Articles')\n",
    "axes[0].tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage distribution\n",
    "axes[1].pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%',\n",
    "            startangle=90, colors=sns.color_palette('pastel'))\n",
    "axes[1].set_title('Source Distribution (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path.cwd().parent / 'data' / 'processed' / 'source_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Source analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4801a1e",
   "metadata": {},
   "source": [
    "### 5. Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "category_counts = df['category'].value_counts()\n",
    "bars = ax.barh(category_counts.index, category_counts.values, color=sns.color_palette('viridis', len(category_counts)))\n",
    "\n",
    "ax.set_title('Articles by Category', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Number of Articles')\n",
    "ax.set_ylabel('Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3173fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add value labels\n",
    "for i, (cat, count) in enumerate(zip(category_counts.index, category_counts.values)):\n",
    "    ax.text(count, i, f' {count}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path.cwd().parent / 'data' / 'processed' / 'category_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Category analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a25ce2",
   "metadata": {},
   "source": [
    "### 6. Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles over time\n",
    "df_hourly = df.set_index('scraped_at').resample('1H').size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "df_hourly.plot(ax=ax, linewidth=2, color='darkblue')\n",
    "ax.set_title('Article Volume Over Time', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Number of Articles')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path.cwd().parent / 'data' / 'processed' / 'temporal_pattern.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Temporal analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour of day distribution\n",
    "if 'scraped_at' in df.columns:\n",
    "    df['hour'] = df['scraped_at'].dt.hour\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    hour_counts = df['hour'].value_counts().sort_index()\n",
    "    ax.bar(hour_counts.index, hour_counts.values, color='coral')\n",
    "    ax.set_title('Article Distribution by Hour of Day', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Hour of Day')\n",
    "    ax.set_ylabel('Number of Articles')\n",
    "    ax.set_xticks(range(24))\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ Hourly pattern analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189041a",
   "metadata": {},
   "source": [
    "### 7. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'title' in df.columns:\n",
    "    # Title length distribution\n",
    "    df['title_length'] = df['title'].str.len()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(df['title_length'], bins=30, color='skyblue', edgecolor='black')\n",
    "    axes[0].set_title('Title Length Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Title Length (characters)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].axvline(df['title_length'].mean(), color='red', linestyle='--', \n",
    "                    label=f'Mean: {df[\"title_length\"].mean():.0f}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Box plot by source\n",
    "    df.boxplot(column='title_length', by='source', ax=axes[1])\n",
    "    axes[1].set_title('Title Length by Source', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Source')\n",
    "    axes[1].set_ylabel('Title Length')\n",
    "    plt.suptitle('')  # Remove automatic title\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTitle Statistics:\")\n",
    "    print(f\"  Average length: {df['title_length'].mean():.0f} characters\")\n",
    "    print(f\"  Median length: {df['title_length'].median():.0f} characters\")\n",
    "    print(f\"  Range: {df['title_length'].min()}-{df['title_length'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86223195",
   "metadata": {},
   "source": [
    "### 8. Language Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b134abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'language' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    lang_counts = df['language'].value_counts()\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1'][:len(lang_counts)]\n",
    "    \n",
    "    wedges, texts, autotexts = ax.pie(lang_counts.values, \n",
    "                                        labels=lang_counts.index, \n",
    "                                        autopct='%1.1f%%',\n",
    "                                        startangle=90,\n",
    "                                        colors=colors,\n",
    "                                        textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "    \n",
    "    ax.set_title('Language Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ Language analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84790b97",
   "metadata": {},
   "source": [
    "### 9. Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'title' in df.columns:\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    \n",
    "    # Extract all words\n",
    "    all_words = []\n",
    "    for title in df['title'].dropna():\n",
    "        words = re.findall(r'\\b\\w+\\b', title.lower())\n",
    "        all_words.extend([w for w in words if len(w) > 3])  # Filter short words\n",
    "    \n",
    "    # Count frequencies\n",
    "    word_freq = Counter(all_words)\n",
    "    top_words = word_freq.most_common(20)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    words, counts = zip(*top_words)\n",
    "    \n",
    "    bars = ax.barh(range(len(words)), counts, color=sns.color_palette('rocket', len(words)))\n",
    "    ax.set_yticks(range(len(words)))\n",
    "    ax.set_yticklabels(words)\n",
    "    ax.set_xlabel('Frequency')\n",
    "    ax.set_title('Top 20 Most Frequent Words', fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (word, count) in enumerate(top_words):\n",
    "        ax.text(count, i, f' {count}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path.cwd().parent / 'data' / 'processed' / 'word_frequency.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ“ Word frequency analysis complete\")\n",
    "    print(f\"\\nTop 10 words: {', '.join([w for w, c in top_words[:10]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af781d",
   "metadata": {},
   "source": [
    "### 10. Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be204b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Analyzed {len(df)} articles\")\n",
    "print(f\"âœ“ Sources: {df['source'].nunique()}\")\n",
    "print(f\"âœ“ Categories: {df['category'].nunique()}\")\n",
    "print(f\"âœ“ Date range: {(df['scraped_at'].max() - df['scraped_at'].min()).days} days\")\n",
    "print(f\"âœ“ Average title length: {df['title_length'].mean():.0f} characters\")\n",
    "print(\"\\nVisualizations saved to: data/processed/\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714545e",
   "metadata": {},
   "source": [
    "### 11. Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5834c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_report = {\n",
    "    'analysis_date': datetime.now().isoformat(),\n",
    "    'total_articles': len(df),\n",
    "    'sources': df['source'].value_counts().to_dict(),\n",
    "    'categories': df['category'].value_counts().to_dict(),\n",
    "    'languages': df['language'].value_counts().to_dict(),\n",
    "    'date_range': {\n",
    "        'start': df['scraped_at'].min().isoformat(),\n",
    "        'end': df['scraped_at'].max().isoformat(),\n",
    "        'days': (df['scraped_at'].max() - df['scraped_at'].min()).days\n",
    "    },\n",
    "    'text_stats': {\n",
    "        'avg_title_length': float(df['title_length'].mean()),\n",
    "        'median_title_length': float(df['title_length'].median())\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report\n",
    "report_path = Path.cwd().parent / 'data' / 'processed' / 'exploration_summary.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Summary report saved to: {report_path}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\nðŸŽ‰ Exploration complete! Ready for modeling.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
